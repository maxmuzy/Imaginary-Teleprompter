/**
 * M√≥dulo de An√°lise de √Åudio para Detec√ß√£o de Mudan√ßa de Speaker
 * 
 * Usa Web Audio API para monitorar caracter√≠sticas de voz:
 * - RMS (volume) para detectar pausas/sil√™ncio
 * - Centroide espectral para detectar mudan√ßas de timbre
 * 
 * Dispara callbacks quando detecta poss√≠vel troca de speaker
 */

let audioContext = null;
let analyser = null;
let mediaStream = null;
let isAnalyzing = false;

// Configura√ß√µes
const CONFIG = {
    // Detec√ß√£o de sil√™ncio/pausa
    silenceThreshold: 0.01,      // RMS abaixo disso = sil√™ncio
    pauseDuration: 500,          // ms de sil√™ncio para considerar pausa
    
    // Detec√ß√£o de mudan√ßa de voz
    spectralChangeThreshold: 0.3, // Varia√ß√£o percentual no centroide espectral
    voiceChangeWindow: 10,        // Amostras para calcular m√©dia m√≥vel
    
    // An√°lise
    fftSize: 2048,
    sampleInterval: 50           // ms entre an√°lises
};

// Estado
let lastSpeechTime = Date.now();
let spectralHistory = [];
let onSpeakerChangeCallback = null;
let analysisInterval = null;

// Buffers para an√°lise
let frequencyData = null;
let timeDomainData = null;

/**
 * Inicializa o analisador de √°udio
 * @param {MediaStream} stream - Stream do microfone (pode ser obtido do getUserMedia)
 * @param {Function} onSpeakerChange - Callback chamado quando detecta mudan√ßa de speaker
 */
export async function iniciarAnalise(stream, onSpeakerChange) {
    if (isAnalyzing) {
        console.log('üîä Analisador j√° est√° rodando');
        return;
    }
    
    try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = CONFIG.fftSize;
        
        const source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser);
        
        // N√£o conecta ao destination para n√£o criar feedback
        
        frequencyData = new Uint8Array(analyser.frequencyBinCount);
        timeDomainData = new Uint8Array(analyser.fftSize);
        
        mediaStream = stream;
        onSpeakerChangeCallback = onSpeakerChange;
        isAnalyzing = true;
        
        // Inicia loop de an√°lise
        analysisInterval = setInterval(analisarAudio, CONFIG.sampleInterval);
        
        console.log('üîä Analisador de √°udio iniciado');
        console.log(`   - Threshold de sil√™ncio: ${CONFIG.silenceThreshold}`);
        console.log(`   - Dura√ß√£o de pausa: ${CONFIG.pauseDuration}ms`);
        
    } catch (error) {
        console.error('‚ùå Erro ao iniciar analisador:', error);
        throw error;
    }
}

/**
 * Para a an√°lise de √°udio
 */
export function pararAnalise() {
    if (analysisInterval) {
        clearInterval(analysisInterval);
        analysisInterval = null;
    }
    
    if (audioContext) {
        audioContext.close();
        audioContext = null;
    }
    
    analyser = null;
    mediaStream = null;
    isAnalyzing = false;
    spectralHistory = [];
    
    console.log('üîä Analisador de √°udio parado');
}

/**
 * Calcula o RMS (Root Mean Square) do sinal - indica volume
 */
function calcularRMS() {
    analyser.getByteTimeDomainData(timeDomainData);
    
    let sum = 0;
    for (let i = 0; i < timeDomainData.length; i++) {
        const normalized = (timeDomainData[i] - 128) / 128; // -1 a 1
        sum += normalized * normalized;
    }
    
    return Math.sqrt(sum / timeDomainData.length);
}

/**
 * Calcula o centroide espectral - indica "brilho" da voz (timbre)
 * Vozes diferentes t√™m centr√≥ides diferentes
 */
function calcularCentroideEspectral() {
    analyser.getByteFrequencyData(frequencyData);
    
    let numerator = 0;
    let denominator = 0;
    
    for (let i = 0; i < frequencyData.length; i++) {
        const frequency = i * audioContext.sampleRate / analyser.fftSize;
        const magnitude = frequencyData[i];
        
        numerator += frequency * magnitude;
        denominator += magnitude;
    }
    
    if (denominator === 0) return 0;
    return numerator / denominator;
}

/**
 * Detecta mudan√ßa abrupta no centroide espectral
 */
function detectarMudancaEspectral(centroide) {
    spectralHistory.push(centroide);
    
    // Mant√©m janela limitada
    if (spectralHistory.length > CONFIG.voiceChangeWindow * 2) {
        spectralHistory.shift();
    }
    
    // Precisa de hist√≥rico suficiente
    if (spectralHistory.length < CONFIG.voiceChangeWindow) {
        return false;
    }
    
    // Calcula m√©dia das √∫ltimas N amostras
    const recentStart = spectralHistory.length - CONFIG.voiceChangeWindow;
    const recent = spectralHistory.slice(recentStart);
    const older = spectralHistory.slice(Math.max(0, recentStart - CONFIG.voiceChangeWindow), recentStart);
    
    if (older.length === 0) return false;
    
    const mediaRecent = recent.reduce((a, b) => a + b, 0) / recent.length;
    const mediaOlder = older.reduce((a, b) => a + b, 0) / older.length;
    
    // Varia√ß√£o percentual
    if (mediaOlder === 0) return false;
    const variacao = Math.abs(mediaRecent - mediaOlder) / mediaOlder;
    
    return variacao > CONFIG.spectralChangeThreshold;
}

/**
 * Loop principal de an√°lise
 */
function analisarAudio() {
    if (!analyser || !isAnalyzing) return;
    
    const rms = calcularRMS();
    const centroide = calcularCentroideEspectral();
    const agora = Date.now();
    
    // Detecta sil√™ncio (poss√≠vel pausa entre speakers)
    const isSilence = rms < CONFIG.silenceThreshold;
    
    if (isSilence) {
        const pausaDuracao = agora - lastSpeechTime;
        
        // Pausa longa detectada - poss√≠vel troca de speaker
        if (pausaDuracao >= CONFIG.pauseDuration) {
            console.log(`üîá Pausa detectada: ${pausaDuracao}ms`);
            
            if (onSpeakerChangeCallback) {
                onSpeakerChangeCallback({
                    tipo: 'pausa',
                    duracao: pausaDuracao,
                    timestamp: agora
                });
            }
            
            // Reseta hist√≥rico espectral ap√≥s pausa
            spectralHistory = [];
            lastSpeechTime = agora; // Evita disparar m√∫ltiplas vezes
        }
    } else {
        // H√° fala - atualiza timestamp e verifica mudan√ßa de voz
        lastSpeechTime = agora;
        
        // Detecta mudan√ßa abrupta no timbre (mesmo sem pausa)
        if (detectarMudancaEspectral(centroide)) {
            console.log(`üé≠ Mudan√ßa de timbre detectada (centroide: ${centroide.toFixed(0)}Hz)`);
            
            if (onSpeakerChangeCallback) {
                onSpeakerChangeCallback({
                    tipo: 'timbre',
                    centroide: centroide,
                    timestamp: agora
                });
            }
            
            // Reseta hist√≥rico para n√£o disparar repetidamente
            spectralHistory = [];
        }
    }
}

/**
 * Obt√©m o stream do microfone
 * Reutiliza se j√° existir um ativo
 */
export async function obterStreamMicrofone() {
    if (mediaStream && mediaStream.active) {
        return mediaStream;
    }
    
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            }
        });
        console.log('üé§ Stream do microfone obtido');
        return stream;
    } catch (error) {
        console.error('‚ùå Erro ao acessar microfone:', error);
        throw error;
    }
}

/**
 * Ajusta configura√ß√µes em tempo real
 */
export function ajustarConfiguracao(novasConfigs) {
    Object.assign(CONFIG, novasConfigs);
    console.log('‚öôÔ∏è Configura√ß√µes do analisador atualizadas:', CONFIG);
}

/**
 * Retorna status atual do analisador
 */
export function getStatus() {
    return {
        isAnalyzing,
        config: { ...CONFIG },
        historyLength: spectralHistory.length
    };
}
